poetry add hume[microphone] python-dotenv
sudo apt-get --yes update
sudo apt-get --yes install libasound2-dev libportaudio2
import asyncio
import base64
import datetime
import os
from dotenv import load_dotenv
from hume import MicrophoneInterface, Stream
from hume.client import AsyncHumeClient
from hume.empathic_voice.chat.socket_client import ChatConnectOptions
from hume.empathic_voice.chat.types import SubscribeEvent

def extract_top_n_emotions(emotion_scores: dict, n: int) -> dict:
    sorted_emotions = sorted(emotion_scores.items(), key=lambda item: item[1], reverse=True)
    top_n_emotions = {emotion: score for emotion, score in sorted_emotions[:n]}
    return top_n_emotions

def print_emotions(emotion_scores: dict) -> None:
    print(' | '.join([f"{emotion} ({score:.2f})" for emotion, score in emotion_scores.items()]))

def log(text: str) -> None:
    now = datetime.datetime.now(tz=datetime.timezone.utc).strftime("%H:%M:%S")
    print(f"[{now}] {text}")
async def main() -> None:
    load_dotenv()
    HUME_API_KEY = os.getenv("HUME_API_KEY")
    HUME_CONFIG_ID = os.getenv("HUME_CONFIG_ID")
    client = AsyncHumeClient(api_key=HUME_API_KEY)
    ...
async def main() -> None:
    ...
    async def on_message(message: SubscribeEvent):
        # (Completed in later steps)
        ...
    async with client.empathic_voice.chat.connect_with_callbacks(
        options=ChatConnectOptions(config_id=HUME_CONFIG_ID),
        on_open=lambda: print("WebSocket connection opened."),
        on_message=on_message,
        on_close=lambda: print("WebSocket connection closed."),
        on_error=lambda err: print(f"Error: {err}")
    ) as socket:
      # (Completed in later steps)
      ...
async def main() -> None:
    ...
    stream = Stream.new()
    async def on_message(message: SubscribeEvent):
        if message.type == "chat_metadata":
            log(
                f"<{message.type}> Chat ID: {message.chat_id}, Chat Group ID: {message.chat_group_id}"
            )
        elif message.type == "user_message" or message.type == "assistant_message":
            log(f"{message.message.role}: {message.message.content}")
            print_emotions(
                extract_top_n_emotions(dict(message.models.prosody and message.models.prosody.scores or {}), 3)
            )
        elif message.type == "audio_output":
            await stream.put(
                base64.b64decode(message.data.encode("utf-8"))
            )
        elif message.type == "error":
            raise RuntimeError(
                f"Received error message from Hume websocket ({message.code}): {message.message}"
            )
        else:
            log(f"<{message.type}>")
    ...
async def main() -> None:
    ...
    stream = Stream.new()
    ...
    async with client.empathic_voice.chat.connect_with_callbacks(
      ...
    ) as socket:
        await MicrophoneInterface.start(
            socket,
            allow_user_interrupt=False,
            byte_stream=stream
        )
python -c "import sounddevice; print(sounddevice.query_devices())"
# outputs something like
  0 DELL U2720QM, Core Audio (0 in, 2 out)
  1 I, Phone 15 Pro Max Microphone, Core Audio (1 in, 0 out)
>  2 Studio Display Microphone, Core Audio (1 in, 0 out)
  3 Studio Display Speakers, Core Audio (0 in, 8 out)
  4 MacBook Pro Microphone, Core Audio (1 in, 0 out)
<  5 MacBook Pro Speakers, Core Audio (0 in, 2 out)
  6 Pro Tools Audio Bridge 16, Core Audio (16 in, 16 out)
  7 Pro Tools Audio Bridge 2-A, Core Audio (2 in, 2 out)
  8 Pro Tools Audio Bridge 2-B, Core Audio (2 in, 2 out)
  9 Pro Tools Audio Bridge 32, Core Audio (32 in, 32 out)
  10 Pro Tools Audio Bridge 64, Core Audio (64 in, 64 out)
  11 Pro Tools Audio Bridge 6, Core Audio (6 in, 6 out)
  12 Apowersoft Audio Device, Core Audio (2 in, 2 out)
  13 ZoomAudioDevice, Core Audio (2 in, 2 out)
# Specify device 4 in MicrophoneInterface 
await MicrophoneInterface.start(
  socket,
  device=4,
  allow_user_interrupt=False,
  byte_stream=stream
)
# Directly import the sounddevice library
import sounddevice as sd

# Set the default device prior to scheduling audio input task
sd.default.device = 4
if __name__ == "__main__":
    asyncio.run(main())
